import tensorflow as tf
from tensorflow.keras import layers, models

# Define the CNN model for feature extraction
def create_cnn_feature_extractor(input_shape, num_classes):
    model = models.Sequential()

    # Convolutional Layer 1
    model.add(layers.Conv2D(32, (3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=input_shape))
    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))

    # Convolutional Layer 2
    model.add(layers.Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu'))
    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))

    # Convolutional Layer 3
    model.add(layers.Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))
    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))

    # Flatten the output for Fully Connected Layer
    model.add(layers.Flatten())

    # Fully Connected Layer 1
    model.add(layers.Dense(256, activation='relu'))
    model.add(layers.Dropout(0.5))  # Dropout for regularization

    # Fully Connected Layer 2
    model.add(layers.Dense(128, activation='relu'))
    model.add(layers.Dropout(0.5))  # Dropout for regularization

    # Output Layer with Softmax Activation
    model.add(layers.Dense(num_classes, activation='softmax'))

    return model

# Example usage
input_shape = (128, 128, 1)  # Example input shape (W, H, channels)
num_classes = 2  # Binary classification (ASD-positive or ASD-negative)

# Create the model
cnn_model = create_cnn_feature_extractor(input_shape, num_classes)

# Compile the model
cnn_model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])

# Print model summary
cnn_model.summary()

# Example input data (replace with actual data)
import numpy as np
X_train = np.random.rand(100, 128, 128, 1)  # 100 samples of 128x128 matrices
y_train = np.random.randint(0, 2, 100)  # Binary labels for 100 samples

# Train the model
cnn_model.fit(X_train, y_train, epochs=10, batch_size=32)
